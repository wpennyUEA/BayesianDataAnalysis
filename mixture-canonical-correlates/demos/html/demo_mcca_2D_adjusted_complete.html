<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
<!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      -->
<title>demo_mcca_2D_adjusted_complete</title>
<meta name="generator" content="MATLAB 23.2">
<link rel="schema.DC" href="http://purl.org/dc/elements/1.1/">
<meta name="DC.date" content="2025-06-18">
<meta name="DC.source" content="demo_mcca_2D_adjusted_complete.m">
<style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; }

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }
span.typesection { color:#A0522D }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style>
</head>
<body>
<div class="content">
<pre class="codeinput">clear <span class="string">all</span>
close <span class="string">all</span>

<span class="comment">% This script uses MCCA to estimate factor matrices of two data sources</span>
<span class="comment">% with shared latent variables</span>

<span class="comment">% Data points</span>
N = 100;

<span class="comment">% Generate latent variable</span>
z = randn(1,N);

<span class="comment">% Define factor matrices for both clusters</span>
W1{1} = [0.5 -0.3]'; <span class="comment">% for first</span>
W2{1} = [1 -2]';
W1{2} = [-0.3 0.5]'; <span class="comment">% and second cluster</span>
W2{2} = [-2 1]';
<span class="comment">% Means</span>
mu1{1} = [-3 3]'; <span class="comment">% for first</span>
mu2{1} = [-2 2]';
mu1{2} = [2 -2]'; <span class="comment">% and second cluster</span>
mu2{2} = [3 -3]';

<span class="comment">% Observation noise SD</span>
sigma = 0.5;

<span class="comment">% Generate data sources</span>
X1 = []; X2 = [];   <span class="comment">% Empty matrices for data sources</span>
<span class="keyword">for</span> m = 1:2,
    <span class="comment">% Cluster m in data source 1</span>
    X1new = W1{m}*z + mu1{m}*ones(1,N) + sigma*randn(2,N);
    <span class="comment">% Cluster m in data source 2</span>
    X2new = W2{m}*z + mu2{m}*ones(1,N) + sigma*randn(2,N);
    <span class="comment">% Concatenate cluster data horizontally</span>
    X1 = [X1, X1new];
    X2 = [X2, X2new];
<span class="keyword">end</span>

<span class="comment">% MCCA</span>
cca = vbcca (X1,X2,1,2);

<span class="comment">% Display true vs estimated factor matrices and means for both clusters</span>
<span class="keyword">for</span> m=1:2,
    disp(sprintf(<span class="string">'CLUSTER %d'</span>,m));
    disp(<span class="string">'Data source 1:'</span>);
    disp(<span class="string">'True W    Estimated W'</span>);
    disp([W1{m},cca.W1{m}]);
    disp(<span class="string">'True mean    Estimated mean'</span>);
    disp([mu1{m},cca.mu1{m}]);
    disp(<span class="string">'Data source 2:'</span>);
    disp(<span class="string">'True W    Estimated W'</span>);
    disp([W2{m},cca.W2{m}]);
    disp(<span class="string">'True mean    Estimated mean'</span>);
    disp([mu2{m},cca.mu2{m}]);
<span class="keyword">end</span>

<span class="comment">% Plot model evidence over iterations</span>
figure
plot(cca.Fhist);
ylabel(<span class="string">'Model Evidence'</span>);
xlabel(<span class="string">'Number of iterations'</span>);
grid <span class="string">on</span>

<span class="comment">% Define grid range</span>
rx=5;ry=6;
S.xmin=-rx;S.xmax=rx;S.dx=0.1;
S.ymin=-ry;S.ymax=ry;S.dy=0.1;
<span class="comment">% Compute 2D marginal distribution over X1 space conditioned on X2</span>
h2 = vbcca_marginal_2D (cca,S,X1,X2);

<span class="comment">% Predict X1[1] from both X2 variables</span>
con.Gamma1 = [1 0]; <span class="comment">% Select first dimension of x1</span>
con.Gamma2 = eye(2); <span class="comment">% Use both dimensions of x2</span>
<span class="keyword">for</span> n=1:size(X2,2),
    c1_both(n) = vbcca_cond_subspace (cca,X2(:,n),con);
<span class="keyword">end</span>

<span class="comment">% Predict X1[1] from both X2[1] (first dimension only)</span>
con.Gamma1 = [1 0]; <span class="comment">% Only first dimension of x1</span>
con.Gamma2 = [1 0]; <span class="comment">% Use only first dimension of x2</span>
<span class="keyword">for</span> n=1:size(X2,2),
    c1_first(n) = vbcca_cond_subspace (cca,X2(1,n),con);
<span class="keyword">end</span>

<span class="comment">% Predict X1[1] from X2 [2] (second dimension only)</span>
con.Gamma1 = [1 0]; <span class="comment">% Only first dimension of x1</span>
con.Gamma2 = [0 1]; <span class="comment">% Use only second dimension of x2</span>
<span class="keyword">for</span> n=1:size(X2,2),
    c1_second(n) = vbcca_cond_subspace (cca,X2(2,n),con);
<span class="keyword">end</span>

<span class="comment">% Visualise predictions vs original data</span>
figure
plot(X2(1,:),con.Gamma1*X1,<span class="string">'bo'</span>);   <span class="comment">% Original data points</span>
hold <span class="string">on</span>
plot(X2(1,:),c1_both,<span class="string">'r.'</span>);
plot(X2(1,:),c1_first,<span class="string">'k.'</span>);
plot(X2(1,:),c1_second,<span class="string">'g.'</span>);
xlabel(<span class="string">'X2[1]'</span>);
ylabel(<span class="string">'X1[1]'</span>);
legend({<span class="string">'Original Data'</span>,<span class="string">'Both X2'</span>,<span class="string">'X2[1]'</span>,<span class="string">'X2[2]'</span>});

<span class="comment">% Plot predicted vs original X1[1] values</span>
figure
plot(con.Gamma1*X1,c1_both,<span class="string">'ro'</span>);
hold <span class="string">on</span>
plot(con.Gamma1*X1,c1_first,<span class="string">'ko'</span>);
plot(con.Gamma1*X1,c1_second,<span class="string">'go'</span>);
xlabel(<span class="string">'Data'</span>);
ylabel(<span class="string">'Fit'</span>);
legend({<span class="string">'Both X2'</span>,<span class="string">'X2[1]'</span>,<span class="string">'X2[2]'</span>});
</pre>
<pre class="codeoutput">Replicate 1, 4 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Replicate 1, 3 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Replicate 1, 2 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Replicate 1, 1 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Replicate 1, 2 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Replicate 1, 3 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Replicate 1, 2 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Replicate 1, 1 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Replicate 1, 3 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Replicate 1, 3 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Replicate 1, 3 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Replicate 1, 1 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Replicate 1, 3 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Replicate 1, 2 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Replicate 1, 2 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Replicate 1, 1 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Replicate 1, 1 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Replicate 1, 2 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Replicate 1, 4 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Replicate 1, 2 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Replicate 1, 1 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Replicate 1, 4 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Replicate 1, 1 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Replicate 1, 2 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Replicate 1, 1 iterations, total sum of distances = 1176.46.
Best total sum of distances = 1176.46
Iteration8, Lower bound:-1165.8614
Iteration9, Lower bound:-1165.7451
Relative change smaller than the tolerance after9 iterations.
CLUSTER 1
Data source 1:
True W    Estimated W
    0.5000   -0.6129
   -0.3000    0.3773

True mean    Estimated mean
   -3.0000   -2.9664
    3.0000    2.8967

Data source 2:
True W    Estimated W
    1.0000   -0.9447
   -2.0000    1.8458

True mean    Estimated mean
   -2.0000   -1.8712
    2.0000    1.7331

CLUSTER 2
Data source 1:
True W    Estimated W
   -0.3000    0.2571
    0.5000   -0.5835

True mean    Estimated mean
    2.0000    2.0152
   -2.0000   -1.8357

Data source 2:
True W    Estimated W
   -2.0000    1.7499
    1.0000   -0.9801

True mean    Estimated mean
    3.0000    2.7065
   -3.0000   -2.8431

</pre>
<img vspace="5" hspace="5" src="demo_mcca_2D_adjusted_complete_01.png" alt=""> <img vspace="5" hspace="5" src="demo_mcca_2D_adjusted_complete_02.png" alt=""> <img vspace="5" hspace="5" src="demo_mcca_2D_adjusted_complete_03.png" alt=""> <img vspace="5" hspace="5" src="demo_mcca_2D_adjusted_complete_04.png" alt=""> <img vspace="5" hspace="5" src="demo_mcca_2D_adjusted_complete_05.png" alt=""> <p class="footer">
<br>
<a href="https://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2023b</a>
<br>
</p>
</div>
<!--
##### SOURCE BEGIN #####

clear all
close all

% This script uses MCCA to estimate factor matrices of two data sources
% with shared latent variables

% Data points
N = 100;

% Generate latent variable
z = randn(1,N);

% Define factor matrices for both clusters
W1{1} = [0.5 -0.3]'; % for first
W2{1} = [1 -2]';
W1{2} = [-0.3 0.5]'; % and second cluster
W2{2} = [-2 1]';
% Means 
mu1{1} = [-3 3]'; % for first  
mu2{1} = [-2 2]';
mu1{2} = [2 -2]'; % and second cluster
mu2{2} = [3 -3]';

% Observation noise SD
sigma = 0.5;

% Generate data sources
X1 = []; X2 = [];   % Empty matrices for data sources
for m = 1:2,
    % Cluster m in data source 1
    X1new = W1{m}*z + mu1{m}*ones(1,N) + sigma*randn(2,N);
    % Cluster m in data source 2
    X2new = W2{m}*z + mu2{m}*ones(1,N) + sigma*randn(2,N);
    % Concatenate cluster data horizontally
    X1 = [X1, X1new];
    X2 = [X2, X2new];
end

% MCCA
cca = vbcca (X1,X2,1,2);

% Display true vs estimated factor matrices and means for both clusters
for m=1:2,
    disp(sprintf('CLUSTER %d',m));
    disp('Data source 1:');
    disp('True W    Estimated W');
    disp([W1{m},cca.W1{m}]);
    disp('True mean    Estimated mean');
    disp([mu1{m},cca.mu1{m}]);
    disp('Data source 2:');
    disp('True W    Estimated W');
    disp([W2{m},cca.W2{m}]);
    disp('True mean    Estimated mean');
    disp([mu2{m},cca.mu2{m}]);
end

% Plot model evidence over iterations
figure
plot(cca.Fhist);
ylabel('Model Evidence');
xlabel('Number of iterations');
grid on

% Define grid range
rx=5;ry=6;
S.xmin=-rx;S.xmax=rx;S.dx=0.1;
S.ymin=-ry;S.ymax=ry;S.dy=0.1;
% Compute 2D marginal distribution over X1 space conditioned on X2
h2 = vbcca_marginal_2D (cca,S,X1,X2);

% Predict X1[1] from both X2 variables
con.Gamma1 = [1 0]; % Select first dimension of x1
con.Gamma2 = eye(2); % Use both dimensions of x2
for n=1:size(X2,2),
    c1_both(n) = vbcca_cond_subspace (cca,X2(:,n),con);
end

% Predict X1[1] from both X2[1] (first dimension only)
con.Gamma1 = [1 0]; % Only first dimension of x1
con.Gamma2 = [1 0]; % Use only first dimension of x2
for n=1:size(X2,2),
    c1_first(n) = vbcca_cond_subspace (cca,X2(1,n),con);
end

% Predict X1[1] from X2 [2] (second dimension only)
con.Gamma1 = [1 0]; % Only first dimension of x1
con.Gamma2 = [0 1]; % Use only second dimension of x2
for n=1:size(X2,2),
    c1_second(n) = vbcca_cond_subspace (cca,X2(2,n),con);
end

% Visualise predictions vs original data
figure
plot(X2(1,:),con.Gamma1*X1,'bo');   % Original data points
hold on
plot(X2(1,:),c1_both,'r.');
plot(X2(1,:),c1_first,'k.');
plot(X2(1,:),c1_second,'g.');
xlabel('X2[1]');
ylabel('X1[1]');
legend({'Original Data','Both X2','X2[1]','X2[2]'});

% Plot predicted vs original X1[1] values
figure
plot(con.Gamma1*X1,c1_both,'ro');
hold on
plot(con.Gamma1*X1,c1_first,'ko');
plot(con.Gamma1*X1,c1_second,'go');
xlabel('Data');
ylabel('Fit');
legend({'Both X2','X2[1]','X2[2]'});



##### SOURCE END #####
-->
</body>
</html>
