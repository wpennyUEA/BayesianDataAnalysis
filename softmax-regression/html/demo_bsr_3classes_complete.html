<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
<!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      -->
<title>demo_bsr_3classes_complete</title>
<meta name="generator" content="MATLAB 23.2">
<link rel="schema.DC" href="http://purl.org/dc/elements/1.1/">
<meta name="DC.date" content="2025-06-18">
<meta name="DC.source" content="demo_bsr_3classes_complete.m">
<style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; }

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }
span.typesection { color:#A0522D }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style>
</head>
<body>
<div class="content">
<pre class="codeinput">clear <span class="string">all</span>
close <span class="string">all</span>

<span class="comment">% This script uses a Bayesian Softmax Regression model to classify data</span>
<span class="comment">% from a three-class 2D Gaussian mixture model</span>

N=120; <span class="comment">% Data points</span>
Dnoise=0; <span class="comment">% Number of additional noisy inputs (distractors)</span>
disp(sprintf(<span class="string">'Number of spurious predictors added = %d'</span>,Dnoise));
opt.verbose=1;

<span class="comment">% Mixture model parameters</span>
mix.m=3;
<span class="comment">% Means of Gaussian components</span>
mix.state(1).m=[1,1]';
mix.state(2).m=[1,5]';
mix.state(3).m=[3,3]';

<span class="comment">% Covariance matrices and equal priors</span>
<span class="keyword">for</span> i=1:3,
    mix.state(i).C=eye(2);
    mix.state(i).prior=1/3;
<span class="keyword">end</span>

<span class="comment">% Sample N data points</span>
[x,label] = spm_samp_mix (mix,N);

<span class="comment">% Plot data points</span>
<span class="keyword">if</span> opt.verbose
    figure
    col={<span class="string">'rx'</span>,<span class="string">'bx'</span>,<span class="string">'kx'</span>};
    <span class="keyword">for</span> i=1:3,
        ind=find(label==i);
        plot(x(ind,1),x(ind,2),col{i});
        hold <span class="string">on</span>
    <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="comment">% Randomly permute data - avoids order effects</span>
ind = randperm(N);
x = x(ind,:);
label = label(ind,:);

<span class="comment">% Add spurious  predictors (random Gaussian noise)</span>
x = [x,1.65*randn(N,Dnoise),ones(N,1)];

opt.diag=0; <span class="comment">% Full covariance model</span>
opt.verbose=1;

<span class="comment">% Bayesian Softmax Regression model</span>
tic; bsr = bsr_fit (x,label,opt); toc

<span class="comment">% Calculate predictived class probabilities and auxiliary quantities</span>
[y,a] = bsr_output (bsr,x);

<span class="comment">% Log Baues Factors and feature relevance indicators</span>
[logbf,z] = bsr_savage_dickey(bsr); <span class="comment">% Savage-Dickey</span>
disp(<span class="string">' '</span>);
disp(<span class="string">'Log BF, row is class(k), column is feature (d):'</span>);
disp(logbf)
disp(<span class="string">' '</span>);
disp(<span class="string">'z, row is class(k), column is feature (d):'</span>);
disp(z)
disp(<span class="string">' '</span>);
disp(<span class="string">'Sum LogBF over classes:'</span>);
disp(sum(logbf,1)); <span class="comment">% Overall feature importance</span>

<span class="comment">% Calculate updated predictions, auxiliary quantities and modified outputs</span>
[y,a,ymod] = bsr_output (bsr,x);

<span class="comment">% Display predicted class assignments and decision boundaries</span>
<span class="keyword">if</span> opt.verbose
    figure
    col={<span class="string">'rx'</span>,<span class="string">'bx'</span>,<span class="string">'kx'</span>};
    <span class="keyword">for</span> i=1:3,
        [tmp,assign]=max(y');   <span class="comment">% Maximum predicted probability</span>
        ind=find(assign'==i);
        plot(x(ind,1),x(ind,2),col{i});
        hold <span class="string">on</span>
    <span class="keyword">end</span>
    <span class="comment">% Plot decision boundary</span>
    <span class="keyword">if</span> Dnoise==0
        <span class="comment">% If Dnoise&gt;0 there will be &gt; 2 inputs</span>
        bsr_plot_boundary (bsr,x);
    <span class="keyword">end</span>

<span class="keyword">end</span>
</pre>
<pre class="codeoutput">Number of spurious predictors added = 0
Iteration 1, Log Joint = -211.407707 
Iteration 2, Log Joint = -98.555881 
Iteration 3, Log Joint = -81.201424 
Iteration 4, Log Joint = -76.471585 
Iteration 5, Log Joint = -75.550608 
Iteration 6, Log Joint = -75.146381 
Iteration 7, Log Joint = -74.890360 
Iteration 8, Log Joint = -74.729525 
Iteration 9, Log Joint = -74.610987 
Iteration 10, Log Joint = -74.522621 
Iteration 11, Log Joint = -74.449060 
Iteration 12, Log Joint = -74.387357 
Iteration 13, Log Joint = -74.332592 
Iteration 14, Log Joint = -74.284017 
Iteration 15, Log Joint = -74.239819 
Iteration 16, Log Joint = -74.199738 
Iteration 17, Log Joint = -74.162966 
Iteration 18, Log Joint = -74.129335 
Iteration 19, Log Joint = -74.098403 
Iteration 20, Log Joint = -74.070018 
Iteration 21, Log Joint = -74.043894 
Iteration 22, Log Joint = -74.019887 
Iteration 23, Log Joint = -73.997790 
Iteration 24, Log Joint = -73.977469 
Iteration 25, Log Joint = -73.958766 
Iteration 26, Log Joint = -73.941561 
Iteration 27, Log Joint = -73.925725 
Iteration 28, Log Joint = -73.911156 
Iteration 29, Log Joint = -73.897746 
Iteration 30, Log Joint = -73.885407 
Iteration 31, Log Joint = -73.874051 
Iteration 32, Log Joint = -73.863600 
Iteration 33, Log Joint = -73.853982 
Iteration 34, Log Joint = -73.845130 
Iteration 35, Log Joint = -73.836983 
Iteration 36, Log Joint = -73.829486 
Iteration 37, Log Joint = -73.822585 
Elapsed time is 0.056573 seconds.
 
Log BF, row is class(k), column is feature (d):
   -0.9294    6.9990
   12.1796   32.7921
   28.6920   -1.3736

 
z, row is class(k), column is feature (d):
    0.5565    4.0603
    5.1111    8.2804
    7.7349    0.5762

 
Sum LogBF over classes:
   39.9421   38.4175

</pre>
<img vspace="5" hspace="5" src="demo_bsr_3classes_complete_01.png" alt=""> <img vspace="5" hspace="5" src="demo_bsr_3classes_complete_02.png" alt=""> <p class="footer">
<br>
<a href="https://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2023b</a>
<br>
</p>
</div>
<!--
##### SOURCE BEGIN #####

clear all
close all

% This script uses a Bayesian Softmax Regression model to classify data
% from a three-class 2D Gaussian mixture model

N=120; % Data points
Dnoise=0; % Number of additional noisy inputs (distractors)
disp(sprintf('Number of spurious predictors added = %d',Dnoise));
opt.verbose=1;

% Mixture model parameters
mix.m=3;
% Means of Gaussian components
mix.state(1).m=[1,1]';
mix.state(2).m=[1,5]';
mix.state(3).m=[3,3]';

% Covariance matrices and equal priors
for i=1:3,
    mix.state(i).C=eye(2);
    mix.state(i).prior=1/3;
end

% Sample N data points
[x,label] = spm_samp_mix (mix,N);

% Plot data points
if opt.verbose
    figure
    col={'rx','bx','kx'};
    for i=1:3,
        ind=find(label==i);
        plot(x(ind,1),x(ind,2),col{i});
        hold on
    end
end

% Randomly permute data - avoids order effects
ind = randperm(N);
x = x(ind,:);
label = label(ind,:);

% Add spurious  predictors (random Gaussian noise)
x = [x,1.65*randn(N,Dnoise),ones(N,1)];

opt.diag=0; % Full covariance model
opt.verbose=1;

% Bayesian Softmax Regression model
tic; bsr = bsr_fit (x,label,opt); toc

% Calculate predictived class probabilities and auxiliary quantities
[y,a] = bsr_output (bsr,x);

% Log Baues Factors and feature relevance indicators
[logbf,z] = bsr_savage_dickey(bsr); % Savage-Dickey
disp(' ');
disp('Log BF, row is class(k), column is feature (d):');
disp(logbf)
disp(' ');
disp('z, row is class(k), column is feature (d):');
disp(z)
disp(' ');
disp('Sum LogBF over classes:');
disp(sum(logbf,1)); % Overall feature importance

% Calculate updated predictions, auxiliary quantities and modified outputs
[y,a,ymod] = bsr_output (bsr,x);

% Display predicted class assignments and decision boundaries
if opt.verbose
    figure
    col={'rx','bx','kx'};
    for i=1:3,
        [tmp,assign]=max(y');   % Maximum predicted probability
        ind=find(assign'==i);
        plot(x(ind,1),x(ind,2),col{i});
        hold on
    end
    % Plot decision boundary
    if Dnoise==0
        % If Dnoise>0 there will be > 2 inputs
        bsr_plot_boundary (bsr,x);
    end
       
end
##### SOURCE END #####
-->
</body>
</html>
